{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b4b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_datasets\n",
    "from feature_pipeline import *\n",
    "from modelling import train_lightgbm\n",
    "from api_predictor import generate_features_for_api\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce854f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load datasets\n",
    "product_prices, chain_campaigns, product_structures = load_datasets(\n",
    "    \"product_prices.csv\", \"chain_campaigns.csv\", \"product_structures.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887da3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(product_prices.head())\n",
    "print(chain_campaigns.head())\n",
    "print(product_structures.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create training features for each competitor\n",
    "df_A = create_features(\"competitorA\", product_prices, chain_campaigns, product_structures)\n",
    "df_B = create_features(\"competitorB\", product_prices, chain_campaigns, product_structures)\n",
    "\n",
    "print(df_A.head())\n",
    "print(df_B.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split features and target variable\n",
    "X_A = df_A.drop(columns=['pvp_was', 'time_key', 'sku'])\n",
    "y_A = df_A['pvp_was']\n",
    "X_B = df_B.drop(columns=['pvp_was', 'time_key', 'sku'])\n",
    "y_B = df_B['pvp_was']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f853737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save original dtypes for future inference\n",
    "original_dtypes_A = X_A.dtypes.to_dict()\n",
    "original_dtypes_B = X_B.dtypes.to_dict()\n",
    "with open(\"original_dtypes_A.pkl\", \"wb\") as f:\n",
    "    pickle.dump(original_dtypes_A, f)\n",
    "with open(\"original_dtypes_B.pkl\", \"wb\") as f:\n",
    "    pickle.dump(original_dtypes_B, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Split training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_A, X_val_A, y_train_A, y_val_A = train_test_split(X_A, y_A, test_size=0.2, shuffle=False)\n",
    "X_train_B, X_val_B, y_train_B, y_val_B = train_test_split(X_B, y_B, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c06b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train LightGBM models\n",
    "modelA = train_lightgbm(X_train_A, y_train_A, X_val_A, y_val_A)\n",
    "modelB = train_lightgbm(X_train_B, y_train_B, X_val_B, y_val_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4fc350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save models and structures\n",
    "joblib.dump(modelA, \"modelA.pkl\")\n",
    "joblib.dump(modelB, \"modelB.pkl\")\n",
    "\n",
    "print(\"Models and structures saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
